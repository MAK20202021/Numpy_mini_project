# Numpy_mini_project
Numpy is Numerical Python. It is an extensive math library. It improves the speed of the process. It creates multidimentional array data structures that can represent vectors and matrices. In machine learning we need to do feature scaling which is called as mean mormalizing. In this exercise, we took random values between 0 and 10,000 and we made the data between 0 and 1 or sometimes very small range around between -3 and 3 by normalizing. Therefore, the average will be near zero. In this project, there is a good example how to choose data for machine learning algorithm. 60% sets have been chosen as training set, 20% sets have been chosen as cross validation sets and 20% sets have been chosen as test sets. It has been made sure that any of the sets values will not overlap each other.
## Project Motivation
This mini project is for providing a fundamental idea on how to utilize Numpy. It develops the creation of multidimentional array very quickly. Numpy has a variuous built-in functions, that support to do calculations such as mean, standard deviation within very short time and it improves the process speed. It provides the useful support to distribute data for machine learning algorithm. 
## Acknowledgement
This mini project is for Udacity Nanodegree Program (https://www.udacity.com/course/data-scientist-nanodegree--nd025). Thank to Udacity for arranging this project to strengthen our knowledge. This project platform has been taken from Udacity.
## Installation
This project needs Anaconda package(Anaconda3), Jupyter Notebook (6.1.4)

## File Description
The souce code for checking speed for NumPy is Checking_speed_NumPy.ipynb
The source code for mean normalization is in Numpy_Exercise_Mean Normalization.ipynb
## Discussion
After completing this mini project, I understand how easily we can reduce the process time by utilizing this important library Numpy.
