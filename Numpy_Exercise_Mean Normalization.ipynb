{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project (Numpy)\n",
    "Numpy is Numerical Python. It is an extensive math library. It improves the speed of the process. It creates multidimentional array data structures that can represent vectors and matrices. In machine learning we need to do feature scaling which is called as mean mormalizing. In this exercise, we took random values between 0 and 10,000 and we made the data between 0 and 1 or sometimes very small range around between -3 and 3 by normalizing. Therefore, the average will be near zero.\n",
    "In this project, there is a good example how to choose data for machine learning algorithm. 60% sets have been chosen as training set, 20% sets have been chosen as cross validation sets and 20% sets have been chosen as test sets. It has been made sure that any of the sets values will not overlap each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# importing NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Creating a 1000 x 20 ndarray with random integers in the half-open interval [0, 10001).\n",
    "X = np.random.randint(0,10000,(1000,20))\n",
    "\n",
    "# printing the shape of X\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X,axis = 0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X-ave_cols)/std_cols\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. We can varify by calculating the average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9184653865522706e-17\n",
      "-1.731747558009267\n",
      "-1.731747558009267\n",
      "1.7468173779239489\n",
      "1.7468173779239489\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(np.mean(X_norm))\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.min(X_norm,axis=0).mean())\n",
    "print(np.mean(np.sort(X_norm, axis=0)[0]))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(np.max(X_norm,axis=0).mean())\n",
    "print(np.mean(np.sort(X_norm, axis=0)[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Distribution for machine learning \n",
    "\n",
    "We can split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "To make sure that there is no overlap, we can use random permutaion of row indices of X_norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238 460 750  58 724 658 434 571  47 702 986 936 360 114 136 703 768 753\n",
      " 892 513  11  69 458 171 190 497 848 339 250 295 849 754 701 307 519 258\n",
      " 689 706 829 891 800 440 100 962 193 725 522 412 142 468  38 831 695 799\n",
      " 527 737 786 467 227 430 402 330 712  99 597 911 163 894 442  39 935 922\n",
      " 191 292 746 588 132  13 550 419 472 429 788 413 568 716 232 129 930 355\n",
      " 347 133 311 372 839 920 204 755 647 739 270 543 523 778 108 200 106 150\n",
      " 981 408 107 457 479 542 791 381 509 234 826 877 425 508 651 758  91 869\n",
      " 275 805 428 220 260 907 662 700 692 131 561 762 252 996 732 896 231   2\n",
      " 906 492 334 531 358 384 552  30 621 876 253 349  55 494 437 641 789 216\n",
      " 882 315 493 226 688 241 604 213 633 269 369 395 628 654 151 949 331 720\n",
      " 874 686 904 661 999 217 557 318 461 120 665 296 971 953 452 377 183 322\n",
      " 153   6  26 281 255 731 488 113 105 600 777 157 696 590 450 370 714 164\n",
      " 594 995 858 361 465   8  66 218  12 678 155   3 374 924 276 422 289 810\n",
      " 379 392 759 840  48 708 156 592 961 946  33 646 441 423 709 794 282  28\n",
      " 139 850 947 387 303 952 267 116 219 984 781  63 793 421 427 304 524 205\n",
      " 121 979 308 143 857 118 644 895 613 230 683 730  68 117 364 595 337 883\n",
      " 902 619 536 627 790 774 570 202 321 529 471 809 223 819 251 792 240 618\n",
      " 167 868 622 921  73  50 607 964 547 779 254 972  70 498 385 207 815 655\n",
      " 912 582 951  81 918 335 182 824 663 605 394   0 544 511 257  19 297 208\n",
      "  27 704 897 336 134 215 485 350 496 506  54 187 209  82 734 411 866 747\n",
      " 363  59 316 448 332 994 752 711 371 756 572 901 345  29 211 757 261 843\n",
      " 247 127 668 103 102 998 853 521 168 454 145 982 722 248 852 650 865 698\n",
      " 502 184 855 367 818 675 727 666 298  24 549 368 707 615 130 115 280 112\n",
      " 735 274  17 235 327 141 548 847   7 881 726 266 687 119 890 889  86 825\n",
      "  60 122 256 886 648 885 431 177 172 181 634 243  57 867 268  78 624 743\n",
      " 820 489 710 945  93 966 772 801 664 723 397  75 158 713 312 284 943 515\n",
      " 823 632 265 927 144 161 535 110  85 933  90 396 126  87 342 636 822 681\n",
      " 660 577 782 728 765 362 775 954 420   5 975 851 944 690 910 453 398 893\n",
      " 147 766  72 166 926 170 160 845 539 285 401 649 499 776 899 672 991 680\n",
      " 320 406 958 642 963 532 832 447 587 608 614 838 870 540 578 864 495 669\n",
      " 244 903 279 784  76 533  71 444 278 481 691 473 359  98 435 417 560 673\n",
      " 277  14 837 639 909  20 221 246 635 140 721 262 976 525 969 729 558 583\n",
      " 149 564 808 373 878 834 195 125 841 344 913 287 677 638 653 563 973 486\n",
      " 748 783 860 249 546 932 630 863 871 483 482 817 383 694 770 310 859 510\n",
      " 575 503 740  61 462 263 325  74 288 192 534  83 719 844 475 426 104 802\n",
      " 259 186  44 294 393 283 152 670 983 224 123 375 974  46 609 965 764 410\n",
      " 291 491 348 438   9  15 905 993  35 699 749 242 138 403  25 553  77 470\n",
      " 455 500 612 351 376 501 400 898 354 389 306  97 194 480 599 451 797 640\n",
      " 580 409 718 324 555   4  40 856 645 751 929  21 356 111 333 505 404 464\n",
      " 365 424 135 538 745  23 807 180 603 937 693 380 616 923 366 861 302 476\n",
      " 667 938 173 879 154 323 378 917 685 717 950 769 229 388 188 507 601 299\n",
      " 415  56 228 671 528 798  84  92 201  18 811 773 264 463 992 490 785 833\n",
      " 148 432 574  96 357 169 656 942 821 771 813 487 576 880 629 328 767 842\n",
      " 626 816 478 237 174 602 617 846 960 872   1 596 101 338 469 900 763 970\n",
      " 914 197  80 518 733 162 530 919 957 967 272 579 941 137 598  32 916 742\n",
      "  62 804 199 551  49 526 652 407 657 554  88 233 382  43  67 888 977 439\n",
      " 715 175 795 567 319 214 835  37 566 340 828 806 787 399 643 459  22 659\n",
      "  34 520  42 293 556 697 679 273 414  94 386 610 286 873 391 705 271 206\n",
      " 537 309 405 955 189 908 203 346 317 128 674 884 343 504 176 925 418 456\n",
      " 606  79 985 341 581 210 165 875 915 956 593 741 301 620 352 676 589 146\n",
      " 314 559 854  31  36 931 212 445 329 416 326 803 827 353  89 830  45 760\n",
      " 477  10 179 591 980 736 109 222 305 514 978 796 940 198 987 990  51 390\n",
      " 585 443 239 625 862 474 682 512 516 185 517 436 611 744 569 466 887 484\n",
      " 586  95 812  53  65 934 997 780  52 631 541 836 814 545 225 989 124 623\n",
      " 446 313 637 245 236 300 684 928 565 290 178 988 573 968 959 449 584 738\n",
      "  16 433 939 159 562 948  64 761 196  41]\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)\n",
    "print(row_indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can distribute the Data. The Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_row = int(row_indices.shape[0]*0.6)\n",
    "Row_train = row_indices[0:train_row]\n",
    "\n",
    "cross_start = train_row\n",
    "cross_end = train_row + int(row_indices.shape[0]*0.2)\n",
    "Row_crossVal = row_indices[cross_start:cross_end]\n",
    "\n",
    "test_start = cross_end\n",
    "test_end = cross_end + int(row_indices.shape[0]*0.2)\n",
    "Row_test = row_indices[test_start:test_end]\n",
    "\n",
    "# Creating a Training Set\n",
    "X_train = X[Row_train,:]\n",
    "\n",
    "# Creating a Cross Validation Set\n",
    "X_crossVal = X[Row_crossVal,:]\n",
    "\n",
    "# Creating a Test Set\n",
    "X_test = X[Row_test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Checking the distribution\n",
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
